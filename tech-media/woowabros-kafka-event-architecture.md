# Kafka를 활용한 이벤트 기반 아키텍처 구축

> 아래 글은 우아한형제들의 우아콘 2023에서 발표한 [해당 영상](https://www.youtube.com/watch?v=DY3sUeGu74M)을 듣고 정리한 글입니다.
> 
> 영상 날짜: 2023. 12. 22

## Prologue

최근 Kafka 기술에 대해 학습하고 B2C 기반 개인 프로젝트에 적용하는 과정 속에서 실제 회사에서는 Kafka 를 어떻게 활용하고 있는지 궁금했다.

여러 자료 및 영상을 확인하던 중 우아한형제들 회사의 딜리버리 조직팀에서 발표한 영상이 개인적으로 얻어가는 부분들이 많아서 이 글을 작성하게 되었다.

## 왜 이벤트 기반 아키텍처를 사용했나?

딜리버리 조직의 목표는 배달을 잘하는 것이다.

서비스 초기에는 '배달' 도메인만 집중했지만, 이후 연관된 다른 도메인과 여러 요구사항으로 인해 시스템 복잡성이 커졌고 강결합 문제가 발생했다.
- '배달' 도메인 외 다른 연관된 도메인 중 일부 도메인(쿠폰, 통계)은 강한 일관성을 보장하지 않아도 된다.

이러한 강결합 문제를 해결하고 결과적 일관성을 보장하기 위해 이벤트 기반 아키텍처를 선택하게 되었다.

이벤트의 구성요소는 크게 네 가지 요소로 나눈다.
- 대상, 행동, 정보, 시간

이러한 네 가지 요소를 바탕으로 다양한 도메인의 이벤트를 표현할 수 있고, 이를 코드에 적용했다.

이렇게 이벤트 기반 아키텍처 적용 후에 배달 시스템에 대한 복잡도가 줄어들었고, 강한 결합 문제를 해결했다.

또한, 데이터 분석에도 활용할 수 있게 했다.
- 언제 배달이 생성되고 누구에게 배차가 되고 어느 과정을 거쳐 배달이 완료되었는지 -> 도메인 히스토리 파악 가능

이벤트 기반 아키텍처를 사용하면서 주의할 점도 존재한다.
- 행위자 기반의 데이터 정의가 필요하고, 소비처 요구사항에 대한 무분별한 데이터 추가를 주의한다.
- 이벤트의 순서가 중요하다 (배달 생성 -> 배차 완료 -> 픽업 완료 -> 배달 완료)


## 이벤트 파이프라인

이벤트 파이프라인을 위해 `Kafka` 를 선택했다.

Kafka 를 선택한 이유: 순서 보장, 고성능/고가용성, 통합 도구, 전담팀 지원
- 순서 보장: 토픽의 파티션을 통해 Key 별로 순서를 보장할 수 있다. (Key - 배달 번호)
- 고성능/고가용성: 실시간 많은 이벤트를 처리하기 위해 필요하다.
- 통합 도구: Kafka Streams, Kafka Connect 등 다양한 통합 도구를 제공한다.
- 전담 팀 지원: 카프카 클러스터 관리, 모니터링 및 지원도구 제공 (카프카 팀이 따로 존재했음)

Kafka 를 도입하면서 예기치 못한 문제가 발생했다.
- 네트워크 이슈, 브로커 이슈 등 이벤트 발행이 실패가 되거나 재시도 처리로 인해 도메인의 상태와 이벤트 발행 결과 간의 불일치 문제가 발생했다.
- 이러한 문제를 해결하기 위해 `Transactional outbox Pattern` 을 도입하게 되었다.
  - 해당 기술을 통해 이벤트 유실과 이벤트 순서 변경에 대한 문제를 해결할 수 있다고 생각했다.
- 이러한 패턴을 도입하면서 `Message Relay` 를 구현해야 했고, 세 가지를 고려했다.
  - 저비용, 안전성, 처리량
  - 직접 구현 대신 오픈소스 플랫폼에서 제공되는 `Debezium` 을 사용했다. -> CDC에서 자주 사용되는 도구
- 이를 통해 이벤트 유실 없이 순서를 보장하는 이벤트 기반 아키텍처를 구축할 수 있었다.

## 이벤트의 활용 사례

순서가 보장된 이벤트는 이벤트 스트림을 구성한다. -> 시스템 개선이나 확장성에 도움이 된다.

찻 번째는 CQRS를 적용했다.
- 대량의 데이터를 조회하기 위해 쿼리 모델을 구축했다.
- 기존의 조회 기능을 쿼리 모델에 사용함으로써 장애가 발생해도 Command 쪽에 영향이 가지 않도록 했다.

두 번째로 데이터 분석 환경을 구축했다.
- 배경: 서비스를 운영하다보면 이슈 대응, 모니터링, 성과 분석을 위해 데이터 분석이 필요했다.
- AWS 기반으로 데이터를 S3 저장 -> 이후 데이터 분석을 위해 AWS Glue, Athena를 활용했다.
- 그리고 다른 팀이 '배달' 도메인에 대한 데이터를 분석할 수 있도록 -> Airflow, (전사적으로 사용하는) DataLake 에 연동했다. 

마지막으로 실시간 배달과 라이더 수를 집계하고 모니터링하기 위해 스트림즈 애플리케이션을 구현했다.
- 기존에는 배치 작업으로 구현했으나, 실시간성을 보장받지 못했다.
- Kafka Streams 를 통해 실시간으로 다양한 지표를 집계해서 모니터링 환경을 구축했다.

## Summary & Review

우아한형제들 회사는 배달의민족 앱을 운영하고 있고, 해당 서비스는 2025년 기준 매달 2,100만명(월간 활성 이용자 수, MAU)으로 많은 사람들이 이용하는 큰 서비스다.

> 관련 자료: [배민 출시 15주년··· 주문 수 65억 건, 거래액 153조원 돌파](https://www.woowahan.com/report/detail/952) / 날짜: 2025. 06. 30

그리고 딜리버리 조직팀에서는 '배달' 도메인을 전담하고 있다.

해당 팀에서는 많은 사용자가 유입되는 큰 트래픽을 안정적으로 처리하면서 배달 순서와 실시간성이 보장되어야 했다.

그렇기 때문에, Kafka 라는 기술을 도입했고 내부의 여러 기능을 사용해서 문제를 해결했고, 그 외 다른 여러 서비스에도 활용한 것이다.
- 굵직한 요구사항으로 정리하면 -> MAU 기준 약 2,100만명 + 순서보장 + 실시간성
- 또한, 회사 내부에 (해당 기술에 대해 전문적으로 잘 알고 있는) 카프카팀이 존재했고, 인프라 지원에 대한 비용도 넉넉히 제공해주는 걸로 보였다.

만약 사용자가 배달의민족앱 처럼 MAU 가 높지 않고, 순서 보장과 실시간성이 아니라면 -> 굳이 이벤트 기반 아키텍처를 도입하지 않아도 된다고 생각한다.

어떠한 기술을 선택하고 도입하기 전에 충분히 비즈니스와 회사 상황을 고려하자. -> 뭐든지 Trade Off 고려 !!
- 비즈니스 상황(월간 활성 이용자 수, 순서보장, 실시간성, 데이터 분석 활용 등)
- 회사 상황(팀 인원, 인프라 지원, 기술 숙련자 등)